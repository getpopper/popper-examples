- hosts: all
  roles:
  - { role: geerlingguy.docker }
- hosts: master
  tasks:
  - name: run spark master
    shell: >
      docker run --name spark-master
      -p 7077:7077 -p 8080:8080
      -e SPARK_LOCAL_IP=0.0.0.0
      -e SPARK_MASTER_HOST=0.0.0.0
      -e ENABLE_INIT_DAEMON=false
      -d
      popperized/spark-master

- hosts: workers
  tasks:
  - name: run spark worker
    shell: >
      docker run --name spark-worker
      -p 8081:8081
      -e ENABLE_INIT_DAEMON=false
      -e SPARK_MASTER='spark://{{ hostvars[groups["master"][0]]["ansible_default_ipv4"]["address"] }}:7077'
      -d
      popperized/spark-worker
- hosts: master
  tasks:
  - name: copy config files
    copy:
      src: ../spark_confs
      dest: /tmp
  - name: run benchmark
    shell: >
      docker run --rm --name spark-submit
      -e SPARK_MASTER_HOST='spark://{{ hostvars[groups["master"][0]]["ansible_default_ipv4"]["address"] }}:7077'
      -v /tmp/spark_confs:/tmp/spark_confs
      --entrypoint=/spark-bench/bin/spark-bench.sh
      popperized/spark-master /tmp/spark_confs/minimal.conf
  - name: run benchmark config A
    shell: >
      docker run --name spark-configA
      -e SPARK_MASTER_HOST='spark://{{ hostvars[groups["master"][0]]["ansible_default_ipv4"]["address"] }}:7077'
      -v /tmp/spark_confs:/tmp/spark_confs
      --entrypoint=/spark-bench/bin/spark-bench.sh
      popperized/spark-master /tmp/spark_confs/classicA.conf
  - name: copy from random file A
    shell: >
      cat /tmp/spark_confs/outA.csv/* > /tmp/outA.csv
  - name: Retreive result A
    fetch:
      src: /tmp/outA.csv
      dest: ../results/
      flat: yes
  - name: run benchmark config B
    shell: >
      docker run --name spark-configB
      -e SPARK_MASTER_HOST='spark://{{ hostvars[groups["master"][0]]["ansible_default_ipv4"]["address"] }}:7077'
      -v /tmp/spark_confs:/tmp/spark_confs
      --entrypoint=/spark-bench/bin/spark-bench.sh
      popperized/spark-master /tmp/spark_confs/classicB.conf
  - name: copy from random file B
    shell: >
      cat /tmp/spark_confs/outB.csv/* > /tmp/outB.csv
  - name: Retreive result B
    fetch:
      src: /tmp/outB.csv
      dest: ../results/
      flat: yes